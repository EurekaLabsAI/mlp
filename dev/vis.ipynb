{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rich extension is already loaded. To reload it, use:\n",
      "  %reload_ext rich\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import math\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from rich import print\n",
    "from common import RNG\n",
    "%load_ext rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab\n",
    "# \"train\" the Tokenizer, so we're able to map between characters and tokens\n",
    "train_text = open(\"../data/train.txt\", \"r\").read()\n",
    "assert all(c == \"\\n\" or (\"a\" <= c <= \"z\") for c in train_text)\n",
    "uchars = sorted(list(set(train_text)))  # unique characters we see in the input\n",
    "vocab_size = len(uchars)\n",
    "char_to_token = {c: i for i, c in enumerate(uchars)}\n",
    "token_to_char = {i: c for i, c in enumerate(uchars)}\n",
    "EOT_TOKEN = char_to_token[\"\\n\"]  # designate \\n as the delimiting <|endoftext|> token\n",
    "# pre-tokenize all the splits one time up here\n",
    "test_tokens = [char_to_token[c] for c in open(\"../data/test.txt\", \"r\").read()]\n",
    "val_tokens = [char_to_token[c] for c in open(\"../data/val.txt\", \"r\").read()]\n",
    "train_tokens = [char_to_token[c] for c in open(\"../data/train.txt\", \"r\").read()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(tokens, context_length, batch_size):\n",
    "    # returns inputs, targets as torch Tensors of shape (B, T), (B, )\n",
    "    n = len(tokens)\n",
    "    inputs, targets = [], []\n",
    "    pos = 0\n",
    "    while True:\n",
    "        # simple sliding window over the tokens, of size context_length + 1\n",
    "        window = tokens[pos : pos + context_length + 1]\n",
    "        inputs.append(window[:-1])\n",
    "        targets.append(window[-1])\n",
    "        # once we've collected a batch, emit it\n",
    "        if len(inputs) == batch_size:\n",
    "            yield (torch.tensor(inputs), torch.tensor(targets))\n",
    "            inputs, targets = [], []\n",
    "        # advance the position and wrap around if we reach the end\n",
    "        pos += 1\n",
    "        if pos + context_length >= n:\n",
    "            pos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, context_length, embedding_size, hidden_size, rng):\n",
    "        super().__init__()\n",
    "        self.wte = nn.Embedding(vocab_size, embedding_size)  # token embedding table\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(context_length * embedding_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, vocab_size),\n",
    "        )\n",
    "        self.reinit(rng)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reinit(self, rng):\n",
    "        # This function is a bit of a hack and would not be present in\n",
    "        # typical PyTorch code. Basically:\n",
    "        # - we want to use our own RNG to initialize the weights.\n",
    "        # - but we don't want to change idiomatic PyTorch code (above).\n",
    "        # So here in this function we overwrite the weights using our own RNG.\n",
    "        # This ensures that we have full control over the initialization and\n",
    "        # can easily compare the results with other implementations.\n",
    "\n",
    "        def reinit_tensor_randn(w, mu, sigma):\n",
    "            winit = torch.tensor(rng.randn(w.numel(), mu=mu, sigma=sigma))\n",
    "            w.copy_(winit.view_as(w))\n",
    "\n",
    "        def reinit_tensor_rand(w, a, b):\n",
    "            winit = torch.tensor(rng.rand(w.numel(), a=a, b=b))\n",
    "            w.copy_(winit.view_as(w))\n",
    "\n",
    "        # Let's match the PyTorch default initialization:\n",
    "        # Embedding with N(0,1)\n",
    "        reinit_tensor_randn(self.wte.weight, mu=0, sigma=1.0)\n",
    "        # Linear (both W,b) with U(-K, K) where K = 1/sqrt(fan_in)\n",
    "        scale = (self.mlp[0].in_features) ** -0.5\n",
    "        reinit_tensor_rand(self.mlp[0].weight, -scale, scale)\n",
    "        reinit_tensor_rand(self.mlp[0].bias, -scale, scale)\n",
    "        scale = (self.mlp[2].in_features) ** -0.5\n",
    "        reinit_tensor_rand(self.mlp[2].weight, -scale, scale)\n",
    "        reinit_tensor_rand(self.mlp[2].bias, -scale, scale)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.size()\n",
    "        emb = self.wte(idx)  # (B, T, embedding_size)\n",
    "        emb = emb.view(B, -1)  # (B, T * embedding_size)\n",
    "        logits = self.mlp(emb)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m27\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mwte\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m27\u001b[0m, \u001b[1;36m48\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mSequential\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m144\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mTanh\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m512\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m27\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_length = 3  # if 3 tokens predict the 4th, this is a 4-gram model\n",
    "embedding_size = 48\n",
    "hidden_size = 512\n",
    "batch_size = 16\n",
    "num_steps = 1000\n",
    "learning_rate = 7e-4\n",
    "init_rng = RNG(1337)\n",
    "model = MLP(vocab_size, context_length, embedding_size, hidden_size, init_rng)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def eval_split(model, tokens, max_batches=None):\n",
    "    # calculate the loss on the given tokens\n",
    "    total_loss = 0\n",
    "    num_batches = len(tokens) // batch_size\n",
    "    if max_batches is not None:\n",
    "        num_batches = min(num_batches, max_batches)\n",
    "    data_iter = dataloader(tokens, context_length, batch_size)\n",
    "    for _ in range(num_batches):\n",
    "        inputs, targets = next(data_iter)\n",
    "        logits, loss = model(inputs, targets)\n",
    "        total_loss += loss.item()\n",
    "    mean_loss = total_loss / num_batches\n",
    "    return mean_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    # logits here is a (1D) torch.Tensor of shape (V,)\n",
    "    maxval = torch.max(logits)  # subtract max for numerical stability\n",
    "    exps = torch.exp(logits - maxval)\n",
    "    probs = exps / torch.sum(exps)\n",
    "    return probs\n",
    "\n",
    "\n",
    "def sample_discrete(probs, coinf):\n",
    "    # sample from a discrete distribution\n",
    "    # probs is a torch.Tensor of shape (V,)\n",
    "    cdf = 0.0\n",
    "    for i, prob in enumerate(probs):\n",
    "        cdf += prob\n",
    "        if coinf < cdf:\n",
    "            return i\n",
    "    return len(probs) - 1  # in case of rounding errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_iter = dataloader(train_tokens, context_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(train_data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">step    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> | train_loss <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.380267</span> | val_loss <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.316255</span> | lr <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.828698e-04</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "step    \u001b[1;36m100\u001b[0m | train_loss \u001b[1;36m2.380267\u001b[0m | val_loss \u001b[1;36m2.316255\u001b[0m | lr \u001b[1;36m6.828698e-04\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step = 100\n",
    "# cosine learning rate schedule, from max lr to 0\n",
    "lr = learning_rate * 0.5 * (1 + math.cos(math.pi * step / num_steps))\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group[\"lr\"] = lr\n",
    "# every now and then evaluate the validation loss\n",
    "last_step = step == num_steps - 1\n",
    "if step % 100 == 0 or last_step:\n",
    "    train_loss = eval_split(model, train_tokens, max_batches=20)\n",
    "    val_loss = eval_split(model, val_tokens)\n",
    "    print(\n",
    "        f\"step {step:6d} | train_loss {train_loss:.6f} | val_loss {val_loss:.6f} | lr {lr:e}\"\n",
    "    )\n",
    "# # training step\n",
    "\n",
    "# get the next batch of training data\n",
    "inputs, targets = next(train_data_iter)\n",
    "# forward pass (calculate the loss)\n",
    "logits, loss = model(inputs, targets)\n",
    "# backpropagate pass (calculate the gradients)\n",
    "loss.backward()\n",
    "# step the optimizer (update the parameters)\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "type": "scatter",
         "x": [
          "\n",
          "a",
          "b",
          "c",
          "d",
          "e",
          "f",
          "g",
          "h",
          "i",
          "j",
          "k",
          "l",
          "m",
          "n",
          "o",
          "p",
          "q",
          "r",
          "s",
          "t",
          "u",
          "v",
          "w",
          "x",
          "y",
          "z"
         ],
         "y": [
          0.1859021,
          0.013671314,
          0.0048392112,
          0.012519657,
          0.008962866,
          0.040073007,
          0.0016011724,
          0.003122163,
          0.11265954,
          0.07040465,
          0.0057795476,
          0.011318369,
          0.016241869,
          0.019599063,
          0.3244852,
          0.005423408,
          0.002861134,
          0.0009918745,
          0.018429052,
          0.028023714,
          0.015435088,
          0.013403041,
          0.006866997,
          0.015201065,
          0.0018444291,
          0.05494936,
          0.005391027
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logits as probabilities of the next token \n    \n    Input: rla | Target: i"
        },
        "xaxis": {
         "title": {
          "text": "Token"
         }
        },
        "yaxis": {
         "title": {
          "text": "Probability"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize logits as probabilities of the next token\n",
    "logits_vis = logits[12]\n",
    "\n",
    "# convert logits to probabilities\n",
    "probs = softmax(logits_vis)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[token_to_char[i] for i in range(vocab_size)],\n",
    "        y=probs.detach().numpy(),\n",
    "        mode=\"lines+markers\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"\"\"Logits as probabilities of the next token <br>\n",
    "    Input: {''.join([token_to_char[i.item()] for i in inputs[12]])} | Target: {token_to_char[targets[12].item()]}\"\"\",\n",
    "    xaxis_title=\"Token\",\n",
    "    yaxis_title=\"Probability\",\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
